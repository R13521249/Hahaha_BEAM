{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install torch==2.0.1 torchvision==0.15.2 --index-url https://download.pytorch.org/whl/cu118\n",
        "!pip install numpy==1.26.4\n",
        "!pip install ultralytics"
      ],
      "metadata": {
        "id": "8_2YwtX6XJ9r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Au1OgdhbuLwX"
      },
      "outputs": [],
      "source": [
        "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "# 0. æ›è¼‰èˆ‡è³‡æ–™æº–å‚™\n",
        "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "import os, random, shutil\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "from tqdm import tqdm\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
        "from torch.utils.data import Dataset, DataLoader, random_split\n",
        "from torchvision import transforms\n",
        "from torchvision.models import efficientnet_v2_s, EfficientNet_V2_S_Weights\n",
        "\n",
        "from sklearn.metrics import f1_score, classification_report\n",
        "from ultralytics import YOLO\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "\n",
        "# è·¯å¾‘è¨­å®š\n",
        "base_drive = '/content/drive/MyDrive/Competition2/Competition/'\n",
        "path_dataset = '/content/dataset_beam/beam_damage/'\n",
        "test_folder = '/content/dataset_beam/test/'\n",
        "src_dir = '/content/drive/MyDrive/Competition2/Competition/dataset_beam/beam_crack'\n",
        "dst_dir = '/content/dataset_beam/beam_crack'\n",
        "cls_ckpt = '/content/best_multitask_model.pth'\n",
        "yolo_ckpt = '/content/runs/detect/yolov8_beam_crack_aug/weights/best.pt'\n",
        "output_csv = '/content/beam_submission.csv'\n",
        "\n",
        "os.makedirs('/content/dataset_beam', exist_ok=True)\n",
        "if not os.path.exists(path_dataset):\n",
        "    shutil.copytree(base_drive + 'dataset_beam/beam_damage/', path_dataset)\n",
        "if not os.path.exists(test_folder):\n",
        "    shutil.copytree(base_drive + 'dataset_beam/test/', test_folder)\n",
        "if not os.path.exists(dst_dir):\n",
        "    shutil.copytree(src_dir, dst_dir)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from collections import Counter\n",
        "\n",
        "# === è¨­å®šä½ çš„æ¨™è¨»æª”è·¯å¾‘ ===\n",
        "label_folder = '/content/dataset_beam/beam_crack/train/labels'\n",
        "\n",
        "# ç”¨ä¾†çµ±è¨ˆæ¯å€‹ class_id å‡ºç¾æ¬¡æ•¸\n",
        "class_counter = Counter()\n",
        "\n",
        "# é€ä¸€è®€å–æ¯å€‹ .txt æ¨™è¨»æª”\n",
        "for file_name in os.listdir(label_folder):\n",
        "    if not file_name.endswith('.txt'):\n",
        "        continue\n",
        "    file_path = os.path.join(label_folder, file_name)\n",
        "    with open(file_path, 'r') as f:\n",
        "        for line in f:\n",
        "            if line.strip():\n",
        "                class_id = int(line.strip().split()[0])\n",
        "                class_counter[class_id] += 1\n",
        "\n",
        "# è¼¸å‡ºçµæœ\n",
        "print(\"ğŸ“Š å„é¡åˆ¥ï¼ˆclass_idï¼‰å‡ºç¾æ¬¡æ•¸ï¼š\")\n",
        "for class_id, count in sorted(class_counter.items()):\n",
        "    print(f\"  class_id= {class_id} ï¼š{count} æ¬¡\")\n"
      ],
      "metadata": {
        "id": "JtsL7BirTPO0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "# âœ… 1. CNN æ¶æ§‹èˆ‡è¨“ç·´ (EfficientNetV2-S)\n",
        "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "CLASS2IDX = {'A': 0, 'B': 1, 'C': 2}\n",
        "IDX2LABEL18 = {0: 18, 1: 19, 2: 20}\n",
        "CRIT_BY_CLS_BEAM = {\n",
        "    0: [0],\n",
        "    1: [3, 4, 6, 8],\n",
        "    2: [1]\n",
        "}\n",
        "N_CRIT = 11\n",
        "\n",
        "tf_train = transforms.Compose([\n",
        "    transforms.RandomResizedCrop(224, scale=(0.8, 1.0)),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "tf_test = transforms.Compose([\n",
        "    transforms.Resize(256),\n",
        "    transforms.CenterCrop(224),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "class BeamDataset(Dataset):\n",
        "    def __init__(self, root_dir, transform=None):\n",
        "        self.paths, self.cls_labels = [], []\n",
        "        self.transform = transform\n",
        "        for cls_name in os.listdir(root_dir):\n",
        "            if cls_name not in CLASS2IDX: continue\n",
        "            cls_idx = CLASS2IDX[cls_name]\n",
        "            cls_folder = os.path.join(root_dir, cls_name)\n",
        "            for img_name in os.listdir(cls_folder):\n",
        "                if not img_name.endswith('.jpg'): continue\n",
        "                self.paths.append(os.path.join(cls_folder, img_name))\n",
        "                self.cls_labels.append(cls_idx)\n",
        "    def __len__(self): return len(self.paths)\n",
        "    def __getitem__(self, i):\n",
        "        img = Image.open(self.paths[i]).convert('RGB')\n",
        "        if self.transform: img = self.transform(img)\n",
        "        return img, self.cls_labels[i]\n",
        "\n",
        "class MultiTaskNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        base = efficientnet_v2_s(weights=EfficientNet_V2_S_Weights.DEFAULT)\n",
        "        self.backbone = nn.Sequential(*list(base.features))\n",
        "        self.pool = nn.AdaptiveAvgPool2d(1)\n",
        "        in_ch = base.classifier[1].in_features\n",
        "        self.cls_head = nn.Sequential(nn.Dropout(0.5), nn.Linear(in_ch, 3))\n",
        "    def forward(self, x):\n",
        "        x = self.pool(self.backbone(x))\n",
        "        x = torch.flatten(x, 1)\n",
        "        return self.cls_head(x)\n",
        "\n",
        "def train_cnn():\n",
        "    ds = BeamDataset(path_dataset, transform=tf_train)\n",
        "    tr, va = random_split(ds, [int(0.8*len(ds)), len(ds)-int(0.8*len(ds))])\n",
        "    tr_loader = DataLoader(tr, batch_size=16, shuffle=True)\n",
        "    va_loader = DataLoader(va, batch_size=16)\n",
        "\n",
        "    model = MultiTaskNet().cuda()\n",
        "    loss_fn = nn.CrossEntropyLoss()\n",
        "    opt = optim.Adam(model.parameters(), lr=3e-4)\n",
        "    sch = CosineAnnealingLR(opt, T_max=20)\n",
        "\n",
        "    for ep in range(20):\n",
        "        model.train()\n",
        "        for x, y in tr_loader:\n",
        "            x, y = x.cuda(), y.cuda()\n",
        "            opt.zero_grad()\n",
        "            out = model(x)\n",
        "            loss = loss_fn(out, y)\n",
        "            loss.backward()\n",
        "            opt.step()\n",
        "        sch.step()\n",
        "    torch.save(model.state_dict(), cls_ckpt)\n",
        "    print('âœ“ CNN training finished')\n"
      ],
      "metadata": {
        "id": "N3J9dO0m0-ks"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "# âœ… 2. YOLOv8 è¨“ç·´\n",
        "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "import yaml\n",
        "\n",
        "data_yaml = {\n",
        "    'path': '/content/dataset_beam/beam_crack',\n",
        "    'train': 'train/images',\n",
        "    'val': 'train/images',\n",
        "    'nc': 4,\n",
        "    'names': ['3_xv', '4_cdiag', '6_cvert', '8_chori']\n",
        "}\n",
        "\n",
        "\n",
        "yaml_path = '/content/beam_crack.yaml'\n",
        "with open(yaml_path, 'w') as f:\n",
        "    yaml.dump(data_yaml, f)\n",
        "\n",
        "def train_yolo():\n",
        "    !yolo task=detect mode=train model=yolov8s.pt \\\n",
        "        data={yaml_path} epochs=100 imgsz=640 batch=16 \\\n",
        "        name=yolov8_beam_crack_aug pretrained=True\n"
      ],
      "metadata": {
        "id": "mmjioheQ2q8M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "# âœ… 3. æ¨è«–ï¼šCNN + YOLO æ•´åˆå¾Œè¼¸å‡º CSV\n",
        "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "def predict_beam():\n",
        "    from ultralytics import YOLO\n",
        "    import torch\n",
        "    import pandas as pd\n",
        "    import os\n",
        "    from PIL import Image\n",
        "\n",
        "    # === æ¨¡å‹è¼‰å…¥ ===\n",
        "    model_cnn = MultiTaskNet().cuda()\n",
        "    model_cnn.load_state_dict(torch.load(cls_ckpt))\n",
        "    model_cnn.eval()\n",
        "    model_yolo = YOLO(yolo_ckpt)\n",
        "\n",
        "    yolo_cls_to_crit = {0: 3, 1: 4, 2: 6, 3: 8}\n",
        "    class_thresholds = {0: 0.10, 1: 0.05, 2: 0.10, 3: 0.10}\n",
        "    criteria_class_map = {\n",
        "        18: {0},\n",
        "        19: {3, 4, 6, 8},\n",
        "        20: {1}\n",
        "    }\n",
        "\n",
        "    submission = []\n",
        "\n",
        "    for i in range(1, 51):\n",
        "        img_path = os.path.join(test_folder, f\"{i}.jpg\")\n",
        "        if not os.path.exists(img_path):\n",
        "            print(f\"âŒ ç¼ºå°‘åœ–ç‰‡ï¼š{img_path}\")\n",
        "            submission.append([i, \"20,1\"])\n",
        "            continue\n",
        "\n",
        "        img = Image.open(img_path).convert('RGB')\n",
        "        x = tf_test(img).unsqueeze(0).cuda()\n",
        "        with torch.no_grad():\n",
        "            cls_idx = torch.argmax(model_cnn(x), dim=1).item()\n",
        "        cls_label = IDX2LABEL18[cls_idx]\n",
        "\n",
        "        if cls_label in [18, 20]:\n",
        "            criteria = list(criteria_class_map[cls_label])\n",
        "        else:\n",
        "            preds = model_yolo(img_path, conf=0.001)[0]\n",
        "            crit_conf = []\n",
        "            for box in preds.boxes:\n",
        "                yolo_cls = int(box.cls[0])\n",
        "                conf = float(box.conf[0])\n",
        "                if yolo_cls in yolo_cls_to_crit:\n",
        "                    real_crit = yolo_cls_to_crit[yolo_cls]\n",
        "                    threshold = class_thresholds[yolo_cls]\n",
        "                    if conf >= threshold:\n",
        "                        crit_conf.append((real_crit, conf))\n",
        "\n",
        "            if 0 in [c for c, _ in crit_conf]:\n",
        "                cls_label = 18\n",
        "                criteria = [0]\n",
        "            elif crit_conf:\n",
        "                top_crit = sorted(crit_conf, key=lambda x: -x[1])[0][0]\n",
        "                for cls_id, valid_crits in criteria_class_map.items():\n",
        "                    if top_crit in valid_crits:\n",
        "                        cls_label = cls_id\n",
        "                        break\n",
        "                criteria = sorted({c for c, conf in crit_conf if c in criteria_class_map[cls_label]})\n",
        "            else:\n",
        "                cls_label = 20\n",
        "                criteria = [1]\n",
        "\n",
        "        cls_str = f\"{cls_label},\" + \",\".join(str(c) for c in criteria)\n",
        "        submission.append([i, cls_str])\n",
        "\n",
        "    df = pd.DataFrame(submission, columns=[\"ID\", \"class\"])\n",
        "    df.to_csv(output_csv, index=False)\n",
        "    print(f\"âœ… è¼¸å‡ºæˆåŠŸï¼š{output_csv}\")\n",
        "\n"
      ],
      "metadata": {
        "id": "BfYwQ8b6zk9a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "# âœ… åŸ·è¡Œæµç¨‹ï¼ˆéœ€æ”¾åœ¨ __main__ï¼‰\n",
        "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "if __name__ == '__main__':\n",
        "    train_cnn()\n",
        "    train_yolo()\n",
        "    predict_beam()\n"
      ],
      "metadata": {
        "id": "fXBHm5tm0lNV"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}