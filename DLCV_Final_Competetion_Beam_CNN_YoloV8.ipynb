{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install torch==2.0.1 torchvision==0.15.2 --index-url https://download.pytorch.org/whl/cu118\n",
        "!pip install numpy==1.26.4\n",
        "!pip install ultralytics"
      ],
      "metadata": {
        "id": "8_2YwtX6XJ9r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Au1OgdhbuLwX"
      },
      "outputs": [],
      "source": [
        "# ───────────────────────────────\n",
        "# 0. 掛載與資料準備\n",
        "# ───────────────────────────────\n",
        "import os, random, shutil\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "from tqdm import tqdm\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
        "from torch.utils.data import Dataset, DataLoader, random_split\n",
        "from torchvision import transforms\n",
        "from torchvision.models import efficientnet_v2_s, EfficientNet_V2_S_Weights\n",
        "\n",
        "from sklearn.metrics import f1_score, classification_report\n",
        "from ultralytics import YOLO\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "\n",
        "# 路徑設定\n",
        "base_drive = '/content/drive/MyDrive/Competition2/Competition/'\n",
        "path_dataset = '/content/dataset_beam/beam_damage/'\n",
        "test_folder = '/content/dataset_beam/test/'\n",
        "src_dir = '/content/drive/MyDrive/Competition2/Competition/dataset_beam/beam_crack'\n",
        "dst_dir = '/content/dataset_beam/beam_crack'\n",
        "cls_ckpt = '/content/best_multitask_model.pth'\n",
        "yolo_ckpt = '/content/runs/detect/yolov8_beam_crack_aug/weights/best.pt'\n",
        "output_csv = '/content/beam_submission.csv'\n",
        "\n",
        "os.makedirs('/content/dataset_beam', exist_ok=True)\n",
        "if not os.path.exists(path_dataset):\n",
        "    shutil.copytree(base_drive + 'dataset_beam/beam_damage/', path_dataset)\n",
        "if not os.path.exists(test_folder):\n",
        "    shutil.copytree(base_drive + 'dataset_beam/test/', test_folder)\n",
        "if not os.path.exists(dst_dir):\n",
        "    shutil.copytree(src_dir, dst_dir)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from collections import Counter\n",
        "\n",
        "# === 設定你的標註檔路徑 ===\n",
        "label_folder = '/content/dataset_beam/beam_crack/train/labels'\n",
        "\n",
        "# 用來統計每個 class_id 出現次數\n",
        "class_counter = Counter()\n",
        "\n",
        "# 逐一讀取每個 .txt 標註檔\n",
        "for file_name in os.listdir(label_folder):\n",
        "    if not file_name.endswith('.txt'):\n",
        "        continue\n",
        "    file_path = os.path.join(label_folder, file_name)\n",
        "    with open(file_path, 'r') as f:\n",
        "        for line in f:\n",
        "            if line.strip():\n",
        "                class_id = int(line.strip().split()[0])\n",
        "                class_counter[class_id] += 1\n",
        "\n",
        "# 輸出結果\n",
        "print(\"📊 各類別（class_id）出現次數：\")\n",
        "for class_id, count in sorted(class_counter.items()):\n",
        "    print(f\"  class_id= {class_id} ：{count} 次\")\n"
      ],
      "metadata": {
        "id": "JtsL7BirTPO0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ───────────────────────────────────────────────\n",
        "# ✅ 1. CNN 架構與訓練 (EfficientNetV2-S)\n",
        "# ───────────────────────────────────────────────\n",
        "CLASS2IDX = {'A': 0, 'B': 1, 'C': 2}\n",
        "IDX2LABEL18 = {0: 18, 1: 19, 2: 20}\n",
        "CRIT_BY_CLS_BEAM = {\n",
        "    0: [0],\n",
        "    1: [3, 4, 6, 8],\n",
        "    2: [1]\n",
        "}\n",
        "N_CRIT = 11\n",
        "\n",
        "tf_train = transforms.Compose([\n",
        "    transforms.RandomResizedCrop(224, scale=(0.8, 1.0)),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "tf_test = transforms.Compose([\n",
        "    transforms.Resize(256),\n",
        "    transforms.CenterCrop(224),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "class BeamDataset(Dataset):\n",
        "    def __init__(self, root_dir, transform=None):\n",
        "        self.paths, self.cls_labels = [], []\n",
        "        self.transform = transform\n",
        "        for cls_name in os.listdir(root_dir):\n",
        "            if cls_name not in CLASS2IDX: continue\n",
        "            cls_idx = CLASS2IDX[cls_name]\n",
        "            cls_folder = os.path.join(root_dir, cls_name)\n",
        "            for img_name in os.listdir(cls_folder):\n",
        "                if not img_name.endswith('.jpg'): continue\n",
        "                self.paths.append(os.path.join(cls_folder, img_name))\n",
        "                self.cls_labels.append(cls_idx)\n",
        "    def __len__(self): return len(self.paths)\n",
        "    def __getitem__(self, i):\n",
        "        img = Image.open(self.paths[i]).convert('RGB')\n",
        "        if self.transform: img = self.transform(img)\n",
        "        return img, self.cls_labels[i]\n",
        "\n",
        "class MultiTaskNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        base = efficientnet_v2_s(weights=EfficientNet_V2_S_Weights.DEFAULT)\n",
        "        self.backbone = nn.Sequential(*list(base.features))\n",
        "        self.pool = nn.AdaptiveAvgPool2d(1)\n",
        "        in_ch = base.classifier[1].in_features\n",
        "        self.cls_head = nn.Sequential(nn.Dropout(0.5), nn.Linear(in_ch, 3))\n",
        "    def forward(self, x):\n",
        "        x = self.pool(self.backbone(x))\n",
        "        x = torch.flatten(x, 1)\n",
        "        return self.cls_head(x)\n",
        "\n",
        "def train_cnn():\n",
        "    ds = BeamDataset(path_dataset, transform=tf_train)\n",
        "    tr, va = random_split(ds, [int(0.8*len(ds)), len(ds)-int(0.8*len(ds))])\n",
        "    tr_loader = DataLoader(tr, batch_size=16, shuffle=True)\n",
        "    va_loader = DataLoader(va, batch_size=16)\n",
        "\n",
        "    model = MultiTaskNet().cuda()\n",
        "    loss_fn = nn.CrossEntropyLoss()\n",
        "    opt = optim.Adam(model.parameters(), lr=3e-4)\n",
        "    sch = CosineAnnealingLR(opt, T_max=20)\n",
        "\n",
        "    for ep in range(20):\n",
        "        model.train()\n",
        "        for x, y in tr_loader:\n",
        "            x, y = x.cuda(), y.cuda()\n",
        "            opt.zero_grad()\n",
        "            out = model(x)\n",
        "            loss = loss_fn(out, y)\n",
        "            loss.backward()\n",
        "            opt.step()\n",
        "        sch.step()\n",
        "    torch.save(model.state_dict(), cls_ckpt)\n",
        "    print('✓ CNN training finished')\n"
      ],
      "metadata": {
        "id": "N3J9dO0m0-ks"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ───────────────────────────────────────────────\n",
        "# ✅ 2. YOLOv8 訓練\n",
        "# ───────────────────────────────────────────────\n",
        "import yaml\n",
        "\n",
        "data_yaml = {\n",
        "    'path': '/content/dataset_beam/beam_crack',\n",
        "    'train': 'train/images',\n",
        "    'val': 'train/images',\n",
        "    'nc': 4,\n",
        "    'names': ['3_xv', '4_cdiag', '6_cvert', '8_chori']\n",
        "}\n",
        "\n",
        "\n",
        "yaml_path = '/content/beam_crack.yaml'\n",
        "with open(yaml_path, 'w') as f:\n",
        "    yaml.dump(data_yaml, f)\n",
        "\n",
        "def train_yolo():\n",
        "    !yolo task=detect mode=train model=yolov8s.pt \\\n",
        "        data={yaml_path} epochs=100 imgsz=640 batch=16 \\\n",
        "        name=yolov8_beam_crack_aug pretrained=True\n"
      ],
      "metadata": {
        "id": "mmjioheQ2q8M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ───────────────────────────────────────────────\n",
        "# ✅ 3. 推論：CNN + YOLO 整合後輸出 CSV\n",
        "# ───────────────────────────────────────────────\n",
        "def predict_beam():\n",
        "    from ultralytics import YOLO\n",
        "    import torch\n",
        "    import pandas as pd\n",
        "    import os\n",
        "    from PIL import Image\n",
        "\n",
        "    # === 模型載入 ===\n",
        "    model_cnn = MultiTaskNet().cuda()\n",
        "    model_cnn.load_state_dict(torch.load(cls_ckpt))\n",
        "    model_cnn.eval()\n",
        "    model_yolo = YOLO(yolo_ckpt)\n",
        "\n",
        "    yolo_cls_to_crit = {0: 3, 1: 4, 2: 6, 3: 8}\n",
        "    class_thresholds = {0: 0.10, 1: 0.05, 2: 0.10, 3: 0.10}\n",
        "    criteria_class_map = {\n",
        "        18: {0},\n",
        "        19: {3, 4, 6, 8},\n",
        "        20: {1}\n",
        "    }\n",
        "\n",
        "    submission = []\n",
        "\n",
        "    for i in range(1, 51):\n",
        "        img_path = os.path.join(test_folder, f\"{i}.jpg\")\n",
        "        if not os.path.exists(img_path):\n",
        "            print(f\"❌ 缺少圖片：{img_path}\")\n",
        "            submission.append([i, \"20,1\"])\n",
        "            continue\n",
        "\n",
        "        img = Image.open(img_path).convert('RGB')\n",
        "        x = tf_test(img).unsqueeze(0).cuda()\n",
        "        with torch.no_grad():\n",
        "            cls_idx = torch.argmax(model_cnn(x), dim=1).item()\n",
        "        cls_label = IDX2LABEL18[cls_idx]\n",
        "\n",
        "        if cls_label in [18, 20]:\n",
        "            criteria = list(criteria_class_map[cls_label])\n",
        "        else:\n",
        "            preds = model_yolo(img_path, conf=0.001)[0]\n",
        "            crit_conf = []\n",
        "            for box in preds.boxes:\n",
        "                yolo_cls = int(box.cls[0])\n",
        "                conf = float(box.conf[0])\n",
        "                if yolo_cls in yolo_cls_to_crit:\n",
        "                    real_crit = yolo_cls_to_crit[yolo_cls]\n",
        "                    threshold = class_thresholds[yolo_cls]\n",
        "                    if conf >= threshold:\n",
        "                        crit_conf.append((real_crit, conf))\n",
        "\n",
        "            if 0 in [c for c, _ in crit_conf]:\n",
        "                cls_label = 18\n",
        "                criteria = [0]\n",
        "            elif crit_conf:\n",
        "                top_crit = sorted(crit_conf, key=lambda x: -x[1])[0][0]\n",
        "                for cls_id, valid_crits in criteria_class_map.items():\n",
        "                    if top_crit in valid_crits:\n",
        "                        cls_label = cls_id\n",
        "                        break\n",
        "                criteria = sorted({c for c, conf in crit_conf if c in criteria_class_map[cls_label]})\n",
        "            else:\n",
        "                cls_label = 20\n",
        "                criteria = [1]\n",
        "\n",
        "        cls_str = f\"{cls_label},\" + \",\".join(str(c) for c in criteria)\n",
        "        submission.append([i, cls_str])\n",
        "\n",
        "    df = pd.DataFrame(submission, columns=[\"ID\", \"class\"])\n",
        "    df.to_csv(output_csv, index=False)\n",
        "    print(f\"✅ 輸出成功：{output_csv}\")\n",
        "\n"
      ],
      "metadata": {
        "id": "BfYwQ8b6zk9a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ───────────────────────────────────────────────\n",
        "# ✅ 執行流程（需放在 __main__）\n",
        "# ───────────────────────────────────────────────\n",
        "if __name__ == '__main__':\n",
        "    train_cnn()\n",
        "    train_yolo()\n",
        "    predict_beam()\n"
      ],
      "metadata": {
        "id": "fXBHm5tm0lNV"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}